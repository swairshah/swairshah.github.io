<!DOCTYPE html>
<html lang="en">
<head>
          <title>Notes - Numerical Computing Notes</title>
        <meta charset="utf-8" />
        <link href="https://swairshah.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Notes Full Atom Feed" />
        <link href="https://swairshah.github.io/feeds/linear-algebra-ml-julia.atom.xml" type="application/atom+xml" rel="alternate" title="Notes Categories Atom Feed" />





</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="https://swairshah.github.io/">Notes <strong></strong></a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
            <li class="active"><a href="https://swairshah.github.io/category/linear-algebra-ml-julia.html">Linear-Algebra, ML, Julia</a></li>
            <li><a href="https://swairshah.github.io/category/test.html">Test</a></li>
        </ul></nav><!-- /#menu -->
<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="https://swairshah.github.io/numerical-computing-notes.html" rel="bookmark"
         title="Permalink to Numerical Computing Notes">Numerical Computing Notes</a></h2>
 
  </header>
  <footer class="post-info">
    <time class="published" datetime="2020-04-10T00:00:00-07:00">
      Fri 10 April 2020
    </time>
    <address class="vcard author">
      By           <a class="url fn" href="https://swairshah.github.io/author/swair.html">Swair</a>
    </address>
    <div class="category">
        Category: <a href="https://swairshah.github.io/category/linear-algebra-ml-julia.html">Linear-Algebra, ML, Julia</a>
    </div>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <h2>Errors in numerical computations and condition number</h2>
<p>There are various ways erros creep into numerical computations,
e.g. discretization, modelling, approximation etc.
In many numerical computations we are trying to approximate a solution,
If we don't know the exact solution to say an problem how do we estimate the errors?
For example say we want to find a root <span class="math">\(x_*\)</span> of <span class="math">\(f(x) = 0\)</span>,
and our approxiate solution is <span class="math">\(x_{est}\)</span>, how do we measure error
<span class="math">\(|x_* - x_{est}|\)</span> without knowing  <span class="math">\(x_*\)</span>?</p>
<p>This is an example for the syntax. <span class="dt-note">This is a note that will appear
in a tag in Markdown</span>. [-]And this is the side  comment[-].</p>
<ol>
<li>
<p><strong>Forward Error</strong>: Use a proxy for the actual error as an estimate for the real
    error. E.g. use <span class="math">\(|f(x_*) - f(x_{est})|\)</span> as a proxy for <span class="math">\(|x_* - x_{est}|\)</span>.</p>
</li>
<li>
<p><strong>Backward Error</strong>: Estimate how much change in the problem is necessary
    so that the approximate solution becomes exact? To understand this consider
    solving the system of linear equations <span class="math">\(Ax = b\)</span>. Say we have an approximate
    algorithm which gives us <span class="math">\(x_{est}\)</span>. We can compute <span class="math">\(Ax_{est} = b_{est}\)</span>,
    the change <span class="math">\(b - b_{est}\)</span> is a change in <span class="math">\(b\)</span> (which is part of the problem
    <em>formulation</em> ) can make the approximate solution exact. This is called the
    backward error. In this example computing the forward error would be to compute,
    <span class="math">\(|A^{-1} b - x_{est}|\)</span> which requires a matrix inversion
    (and that computation may itself have errors of its own). Many times its
    easier to compute the backward errors than the forward errors. <span class="dt-note"> this is a note </span></p>
</li>
</ol>
<p><strong>Condition Number</strong>:
A problem is well conditioned if low for backward errors imply low forward errors.
So a small change in the problem (e.g. values of matrix <span class="math">\(A\)</span> in <span class="math">\(Ax = b\)</span>) will
have small change the solution.</p>
<p>In numerical linear algebra we compute the condition number of a matrix to judge
its <em>well-behavedness</em>. The condition number of a matrix A with respect to
a given norm <span class="math">\(\| \cdot \|\)</span> is, |-| this is not working |-|</p>
<p class=framed>
\begin{equation}
    \text{cond}(A) = \frac{\| A \|}{ \| A^{-1} \|}
\end{equation}
</p>

<h2>Gradient Descent</h2>
<div class="highlight"><pre><span></span><code><span class="k">using</span> <span class="n">Flux</span>

<span class="k">abstract</span> <span class="k">type</span> <span class="n">DescentMethod</span> <span class="k">end</span>
<span class="k">struct</span> <span class="n">GradientDescent</span> <span class="o">&lt;:</span> <span class="n">DescentMethod</span>
    <span class="n">α</span>
<span class="k">end</span>

<span class="n">init!</span><span class="p">(</span><span class="n">M</span><span class="o">::</span><span class="n">GradientDescent</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">M</span>
<span class="k">function</span> <span class="n">step!</span><span class="p">(</span><span class="n">M</span><span class="o">::</span><span class="n">GradientDescent</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">α</span><span class="p">,</span> <span class="n">g</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">α</span><span class="p">,</span> <span class="n">∇f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">α</span><span class="o">*</span><span class="n">g</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">minimize</span><span class="p">(</span><span class="n">M</span><span class="o">::</span><span class="n">DescentMethod</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ε</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">init!</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span> <span class="o">:</span> <span class="n">n</span>
        <span class="n">x′</span> <span class="o">=</span> <span class="n">step!</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x′</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">ε</span>
            <span class="k">break</span>
        <span class="k">end</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x′</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">x</span>
<span class="k">end</span><span class="p">;</span>
</code></pre></div>


<p>Lets compare the solution of <code>A\b</code> to the one achieved by
<code>GradientDescent</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">M</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">);</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">M</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">M</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="n">f</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">A</span> <span class="o">*</span> <span class="n">x</span> <span class="o">-</span> <span class="n">b</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">∇f</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">x̂</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">GradientDescent</span><span class="p">(</span><span class="mf">0.05</span><span class="p">),</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">5000</span><span class="p">)</span>

<span class="n">print</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">x̂</span> <span class="o">-</span> <span class="n">A</span><span class="o">\</span><span class="n">b</span><span class="p">))</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="err">67601.23007370268</span>
</code></pre></div>


<h2>Conjugate Gradients</h2>
<div class="highlight"><pre><span></span><code><span class="k">using</span> <span class="n">LinearAlgebra</span><span class="p">,</span> <span class="n">IterativeSolvers</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">diagm</span><span class="p">(</span><span class="mi">100</span><span class="o">:</span><span class="mi">199</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">history</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">true</span><span class="p">)</span>

<span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="o">:</span><span class="n">resnorm</span><span class="p">],</span> <span class="n">legend</span><span class="o">=</span><span class="kc">false</span><span class="p">)</span>
</code></pre></div>


<p><img alt="" src="figures/NumericalAnalysis_4_1.png"></p>
<hr>
<p>References:</p>
<p>[1] Trefethen, Lloyd N., and David Bau III.
    Numerical linear algebra. Vol. 50. Siam, 1997.</p>
<p>[2] Kochenderfer, Mykel J., and Tim A. Wheeler.
    Algorithms for optimization. Mit Press, 2019.</p>
<p>[3]  Solomon, Justin. Numerical algorithms: methods for computer vision,
    machine learning, and graphics. CRC press, 2015.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
  </div><!-- /.entry-content -->
</section>
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>