<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!--script async src="https://www.googletagmanager.com/gtag/js?id=UA-41105501-1"></script-->
  <script type="text/javascript" src="/theme/js/refs_v1.js"> </script> 
  <script type="text/javascript" src="/theme/js/bibtexParse.js"> </script> 
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-41105501-1');
  </script>

  <meta charset="utf-8" />
  <title>Numerical Computing Notes</title>
  <meta name="author" content="Swair" />
  <link rel="stylesheet" type="text/css" href="/theme/tufte-css/tufte.css" />
  <link rel="stylesheet" type="text/css" href="/theme/css/main.css" />
  <link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png" />
  <link rel="shortcut icon" href="/static/favicon.ico" />
  <link rel="icon" type="image/png" href="/static/favicon.png" />

  <!-- OpenGraph Info -->


  <style type="text/css">
    .blue {
      color: blue;
    }
  </style>


</head>

<body>
<header>
  <h1 class="websitetitle"><a href="">Working Notes</a></h1>
  <!-- <nav class="navmenu" id="navmenu">
    <li><a class="navitemlink" href="/archives.html">Archive</a></li>
   </nav> -->
   <nav class="navmenu" id="navmenu">
    <li><a class="navitemlink" href="/pages/about.html">About</a></li>
    <li><a class="navitemlink" href="/">Blog</a></li>
    <li><a class="navitemlink" href="/archives.html">Archive</a></li>
   </nav>
 </header>
<article>

<header class="post-header">
<h1> <a rel="bookmark"
   title="Numerical Computing Notes «Working Notes»"
   href="/numerical-computing-notes.html">
   Numerical Computing Notes
</a>
</h1>
<p class="subtitle"></p>
<p class="articlemeta"><label for="numerical-computing-notes" class="margin-toggle"> ⊕</label><input type="checkbox" id="numerical-computing-notes" class="margin-toggle" />
<span class="marginnote"><br/>
By Swair.
<br/><br />
Category: <a href="/category/numerical-linear-algebra-ml-julia-python.html">Numerical-Linear-Algebra, ML, Julia, Python</a>
<br />
<br /><br/>
<time datetime="2020-04-20T00:00:00-07:00">Mon 20 April 2020</time>

</span>
</p>



</header><div id="TOC"> </div>
<p>I did a fair bit of numerical linear algebra in my gradschool. Most of the time
I used libraries written by my adviser Haim Schweitzer over the years. Some
of the algorithms I came across were wonderful, e.g. Lanczos Iterations,
Power Method. As I never had a proper course in Numerical Analysis
I feel the need to understand some things which I missed. I will keep addind the
notes and references here. I will also include some Julia or Python code.</p>
<h2>Errors in numerical computations and condition number</h2>
<p>There are various ways erros can creep into numerical computations,
e.g. discretization, modelling, approximation etc.
In many numerical computations we are trying to approximate a solution.
If we don't know the exact solution then how can we estimate the errors?
For example say, we want to find a root <span class="math">\(x_*\)</span> of <span class="math">\(f(x) = 0\)</span>,
and our approxiate solution is <span class="math">\(x_{est}\)</span>, how do we measure error
<span class="math">\(|x_* - x_{est}|\)</span> without knowing  <span class="math">\(x_*\)</span>?</p>
<p><strong>Forward Error</strong>: Use a proxy for the actual error as an estimate for the real
error. E.g. use <span class="math">\(|f(x_*) - f(x_{est})|\)</span> as a proxy for <span class="math">\(|x_* - x_{est}|\)</span>.</p>
<p><strong>Backward Error</strong>: Estimate how much change in the problem is necessary
so that the approximate solution becomes exact? To understand this consider
solving the system of linear equations <span class="math">\(Ax = b\)</span>. Assume that we have an
approximate algorithm which gives us <span class="math">\(x_{est}\)</span>. We can compute <span class="math">\(Ax_{est} = b_{est}\)</span>,
the change <span class="math">\(b - b_{est}\)</span> is a change in <span class="math">\(b\)</span> (which is part of the problem
<em>formulation</em> ) can make the approximate solution exact. This is called the
backward error. In this example computing the forward error would be to compute,
<span class="math">\(|A^{-1} b - x_{est}|\)</span> which requires a matrix inversion
(and that computation may itself have errors of its own). Many times its
easier to compute the backward errors than the forward errors.</p>
<h3>Condition Number</h3>
<p>A problem is well conditioned if low for backward errors imply low forward errors.
So a small change in the problem (e.g. values of matrix <span class="math">\(A\)</span> in <span class="math">\(Ax = b\)</span>) will
have small change the solution.</p>
<p>In numerical linear algebra we compute the condition number of a matrix to judge
its <em>well-behavedness</em>. The condition number of a matrix A with respect to
a given norm <span class="math">\(\| \cdot \|\)</span> is,</p>
<p class="equation">
\begin{equation}
    \text{cond}(A) = \frac{\| A \|}{ \| A^{-1} \|}
\end{equation}
</p>

<h2>Gradient Descent</h2>
<div class="highlight"><pre><span></span><code><span class="k">using</span> <span class="n">Flux</span>

<span class="k">abstract</span> <span class="k">type</span> <span class="n">DescentMethod</span> <span class="k">end</span>
<span class="k">struct</span> <span class="n">GradientDescent</span> <span class="o">&lt;:</span> <span class="n">DescentMethod</span>
    <span class="n">α</span>
<span class="k">end</span>

<span class="n">init!</span><span class="p">(</span><span class="n">M</span><span class="o">::</span><span class="n">GradientDescent</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">M</span>
<span class="k">function</span> <span class="n">step!</span><span class="p">(</span><span class="n">M</span><span class="o">::</span><span class="n">GradientDescent</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">α</span><span class="p">,</span> <span class="n">g</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">α</span><span class="p">,</span> <span class="n">∇f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">α</span><span class="o">*</span><span class="n">g</span>
<span class="k">end</span>

<span class="k">function</span> <span class="n">minimize</span><span class="p">(</span><span class="n">M</span><span class="o">::</span><span class="n">DescentMethod</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">ε</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">init!</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="kp">in</span> <span class="mi">1</span> <span class="o">:</span> <span class="n">n</span>
        <span class="n">x′</span> <span class="o">=</span> <span class="n">step!</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x′</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">ε</span>
            <span class="k">break</span>
        <span class="k">end</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x′</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">x</span>
<span class="k">end</span><span class="p">;</span>
</code></pre></div>


<p>Lets compare the solution of <code>A\b</code> to the one achieved by
<code>GradientDescent</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">M</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">);</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">M</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">M</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="n">f</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">A</span> <span class="o">*</span> <span class="n">x</span> <span class="o">-</span> <span class="n">b</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">∇f</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">x̂</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">GradientDescent</span><span class="p">(</span><span class="mf">0.05</span><span class="p">),</span> <span class="n">f</span><span class="p">,</span> <span class="n">∇f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">5000</span><span class="p">)</span>

<span class="n">print</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">x̂</span> <span class="o">-</span> <span class="n">A</span><span class="o">\</span><span class="n">b</span><span class="p">))</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="err">0.07817382271428773</span>
</code></pre></div>


<h2>Conjugate Gradients</h2>
<div class="highlight"><pre><span></span><code><span class="k">using</span> <span class="n">LinearAlgebra</span><span class="p">,</span> <span class="n">IterativeSolvers</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">diagm</span><span class="p">(</span><span class="mi">100</span><span class="o">:</span><span class="mi">199</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">history</span> <span class="o">=</span> <span class="n">cg</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">true</span><span class="p">)</span>

<span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="o">:</span><span class="n">resnorm</span><span class="p">],</span> <span class="n">legend</span><span class="o">=</span><span class="kc">false</span><span class="p">)</span>
</code></pre></div>


<p><img alt="" src="figures/NumericalAnalysis_5_1.png"></p>
<hr>
<p>References:</p>
<p>[1] Trefethen, Lloyd N., and David Bau III.
    Numerical linear algebra. Vol. 50. Siam, 1997.</p>
<p>[2] Kochenderfer, Mykel J., and Tim A. Wheeler.
    Algorithms for optimization. Mit Press, 2019.</p>
<p>[3]  Solomon, Justin. Numerical algorithms: methods for computer vision,
    machine learning, and graphics. CRC press, 2015.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
</article>
<!--div id="disqus_thread"></div-->
<script>
doTOC();
doNotes();    
</script>

<div id="disqus_thread"></div>
    <script>

        /**
        *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
(function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://swairshah-github-io.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
})();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<!-- <footer>
  <p>Powered by <a href="http://pelican.readthedocs.org">Pelican</a></p>
</footer> -->
<!--script id="dsq-count-scr" src="//isaythings.disqus.com/count.js" async></script-->
</body>

</html>